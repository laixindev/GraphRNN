{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import networkx as nx  \n",
    "import matplotlib.pyplot as plt\n",
    "import operator\n",
    "import numpy as np\n",
    "import numpy\n",
    "import sys\n",
    "import json\n",
    "import pdb\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import random\n",
    "np.set_printoptions(threshold=sys.maxsize)\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from read_graph import read_graphs_in_networkx,save_graphs_nx\n",
    "from utils import calculate_M,graphs_db,encode_M_matrix,decode_M_matrix\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CUSTOM_RNN_NODE(torch.nn.Module):\n",
    "    def __init__(self, input_size, embedding_size=64, hidden_size=32,output_size =None,number_layers=4,name=\"\",len_unique_node_labels=None,len_unique_edge_labels=None):\n",
    "        super(CUSTOM_RNN_NODE, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.number_layers = number_layers\n",
    "        self.name = name\n",
    "        self.len_unique_node_labels = len_unique_node_labels\n",
    "        self.len_unique_edge_labels = len_unique_edge_labels\n",
    "        \n",
    "        self.sequence_embedding_size = embedding_size*input_size + embedding_size*4\n",
    "        self.input = nn.Embedding(self.len_unique_edge_labels, embedding_size)\n",
    "        self.input2 = nn.Embedding(self.len_unique_node_labels, embedding_size*4)\n",
    "        self.rnn = nn.GRU(input_size=self.sequence_embedding_size,hidden_size = self.hidden_size,\n",
    "                                num_layers=self.number_layers,bias=True,batch_first=True,dropout=0)\n",
    "        self.hidden_n = None\n",
    "        #self.out = nn.Sequential(nn.Linear(self.hidden_size,self.embedding_size),nn.ReLU(),nn.Linear(self.embedding_size,self.output_size))\n",
    "        self.out = nn.Sequential(nn.Linear(self.hidden_size,self.sequence_embedding_size),nn.ReLU(),nn.Linear(self.sequence_embedding_size,self.output_size))\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        ###MLP for loss\n",
    "        self.Linear = nn.Sequential(nn.ReLU(),nn.Linear(self.output_size,self.len_unique_node_labels))\n",
    "    def forward(self,input,x_node_label, seq_lengths = None,is_packed=True,is_MLP=False):\n",
    "        \n",
    "        input = self.input(input)\n",
    "        input = self.relu(input)\n",
    "        input = input.reshape(input.shape[0],input.shape[1],-1)\n",
    "        input2 = self.input2(x_node_label)\n",
    "        input_concat =torch.cat((input, input2), 2)\n",
    "        if is_packed:\n",
    "            input_concat = pack_padded_sequence(input_concat,seq_lengths,batch_first=True,enforce_sorted=False)\n",
    "        output,self.hidden_n = self.rnn(input_concat,self.hidden_n)\n",
    "        \n",
    "        if is_packed:\n",
    "            output = pad_packed_sequence(output,batch_first=True)[0]\n",
    "        output = self.out(output)\n",
    "        if not is_MLP:\n",
    "            return output\n",
    "        \n",
    "        mlp_output= self.Linear(output)\n",
    "        return output,mlp_output\n",
    "        \n",
    "    def init_hidden(self, batch_size):\n",
    "        return Variable(torch.zeros(self.number_layers, batch_size, self.hidden_size))\n",
    "    \n",
    "class CUSTOM_RNN_EDGE(torch.nn.Module):\n",
    "    def __init__(self, input_size, embedding_size=64, hidden_size=32,output_size =None,number_layers=4,name=\"\",len_unique_edge_labels=None):\n",
    "        super(CUSTOM_RNN_EDGE, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.embedding_size = embedding_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.number_layers = number_layers\n",
    "        self.name = name\n",
    "        self.len_unique_edge_labels = len_unique_edge_labels\n",
    "        \n",
    "        self.embedding= nn.Embedding(self.len_unique_edge_labels,embedding_size)\n",
    "        self.linear = nn.Linear(self.input_size,self.embedding_size)\n",
    "        self.rnn = nn.GRU(input_size=self.embedding_size,hidden_size = self.hidden_size,\n",
    "                                num_layers=self.number_layers,bias=True,batch_first=True,dropout=0)\n",
    "        self.hidden_n = None\n",
    "        self.out = nn.Sequential(nn.Linear(self.hidden_size,self.embedding_size),nn.ReLU(),nn.Linear(self.embedding_size,self.output_size))\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.Linear_mlp = nn.Sequential(nn.ReLU(),nn.Linear(self.output_size,self.len_unique_edge_labels))\n",
    "    def forward(self,input, seq_lengths = None,is_mlp=False):\n",
    "        #print(\"doing forward loop for rnn ,\" ,self.name)\n",
    "        input = self.embedding(input)\n",
    "        input = self.relu(input)\n",
    "        input = input.reshape(input.size(0),input.size(1),-1)\n",
    "        output,self.hidden_n = self.rnn(input,self.hidden_n)\n",
    "        output = self.out(output)\n",
    "        \n",
    "        if not is_mlp:\n",
    "            return output\n",
    "        output_mlp = self.Linear_mlp(output)\n",
    "        return output,output_mlp\n",
    "    \n",
    "    \n",
    "def pick_random_label(label_freq_dict):\n",
    "    freq_dict = [(key,value) for key,value in label_freq_dict.items() ]\n",
    "    freq_dict =sorted(freq_dict,key=lambda val:val[1],reverse=True)\n",
    "    return random.choice((freq_dict[0][0],freq_dict[1][0]))\n",
    "def sample_multi(y,num_of_samples=1):\n",
    "    #print(y)\n",
    "    y = F.softmax(y,dim=2)\n",
    "    sampled_y = torch.mode(torch.multinomial(y.view(y.size(0),y.size(2)),num_samples=num_of_samples,replacement=True))[0]\n",
    "    #print(sampled_y)\n",
    "    return sampled_y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_param = \"../models/\"\n",
    "epoch = 1\n",
    "model_parameters = pickle.load(open(folder_param+\"parameters_\"+str(epoch)+\".pkl\",\"rb\"))\n",
    "\n",
    "\n",
    "        \n",
    "### Define two RNNs 1 for graph level and 2nd for edge level \n",
    "M = model_parameters['M']\n",
    "hidden_size_node_rnn = model_parameters['hidden_size_node_rnn']\n",
    "hidden_size_edge_rnn = model_parameters['hidden_size_edge_rnn']\n",
    "embedding_size_node_rnn = model_parameters['embedding_size_node_rnn']\n",
    "embedding_size_edge_rnn = model_parameters['embedding_size_edge_rnn']\n",
    "num_layers = model_parameters['num_layers']\n",
    "len_node_labels = model_parameters['len_nodes']\n",
    "len_edge_labels = model_parameters['len_edges']\n",
    "node_label_dict = model_parameters['node_label_dict']\n",
    "edge_label_dict = model_parameters['edge_label_dict']\n",
    "node_label_dict = {value:key for key,value in node_label_dict.items()}\n",
    "edge_label_dict = {value:key for key,value in edge_label_dict.items()}\n",
    "node_rnn = CUSTOM_RNN_NODE(input_size=M, embedding_size=embedding_size_node_rnn,\n",
    "                hidden_size=hidden_size_node_rnn, number_layers=num_layers,output_size=len_node_labels,\n",
    "            name=\"node\",len_unique_node_labels=len_node_labels,len_unique_edge_labels=len_edge_labels)\n",
    "edge_rnn = CUSTOM_RNN_EDGE(input_size=1, embedding_size=embedding_size_edge_rnn,\n",
    "                   hidden_size=len_node_labels, number_layers=num_layers, output_size=len_edge_labels,\n",
    "                    name=\"edge\",len_unique_edge_labels=len_edge_labels)\n",
    "\n",
    "\n",
    "fname_node = folder_param + \"node_\" + str(epoch) + \".dat\"\n",
    "fname_edge= folder_param + \"edge_\" + str(epoch) + \".dat\"\n",
    "node_rnn.load_state_dict(torch.load(fname_node))\n",
    "edge_rnn.load_state_dict(torch.load(fname_edge))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'S',\n",
       " 2: 'O',\n",
       " 3: 'N',\n",
       " 4: 'C',\n",
       " 5: 'H',\n",
       " 6: 'Cl',\n",
       " 7: 'F',\n",
       " 8: 'P',\n",
       " 9: 'Br',\n",
       " 10: 'Si',\n",
       " 11: 'I'}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generating\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n"
     ]
    }
   ],
   "source": [
    "num_graphs_to_be_generated = 1000\n",
    "max_num_nodes = model_parameters['max_num_nodes']\n",
    "M = model_parameters['M']\n",
    "num_layers = model_parameters['num_layers']\n",
    "most_frequent_edge_label = model_parameters['most_frequent_edge_label']\n",
    "node_label_freq_dict = model_parameters['node_label_freq_dict']\n",
    "node_rnn.hidden_n = node_rnn.init_hidden(num_graphs_to_be_generated)\n",
    "node_rnn.eval()\n",
    "edge_rnn.eval()\n",
    "generated_graphs =torch.zeros(num_graphs_to_be_generated, max_num_nodes-1, M)\n",
    "generated_graphs_labels = torch.zeros(num_graphs_to_be_generated,max_num_nodes-1,1)\n",
    "node_x = torch.ones(num_graphs_to_be_generated,1,M).long()*most_frequent_edge_label\n",
    "node_x_label = torch.ones(num_graphs_to_be_generated,1).long()\n",
    "for i in range(0,num_graphs_to_be_generated):\n",
    "    node_x_label[i,0]=pick_random_label(node_label_freq_dict)\n",
    "    #node_x_label[i,0] = 2\n",
    "node_x_label_1st_node = node_x_label\n",
    "\n",
    "print(\"generating\")\n",
    "for i in range(0,max_num_nodes-1):\n",
    "    print(i)\n",
    "    h = node_rnn(node_x,node_x_label,None,is_packed=False)\n",
    "    node_label_sampled = sample_multi(h,num_of_samples=1)\n",
    "    h_edge_tmp = torch.zeros(num_layers-1, h.size(0), h.size(2))\n",
    "    edge_rnn.hidden_n = torch.cat((h.permute(1,0,2),h_edge_tmp),dim=0)\n",
    "    edge_x = torch.ones(num_graphs_to_be_generated,1,1).long()*most_frequent_edge_label\n",
    "    \n",
    "    \n",
    "    node_x = torch.zeros(num_graphs_to_be_generated,1,M).long()\n",
    "    node_x_label = node_label_sampled.long()\n",
    "    \n",
    "    \n",
    "    for j in range(min(M,i+1)):\n",
    "        edge_rnn_y_pred = edge_rnn(edge_x)\n",
    "        edge_rnn_y_pred_sampled = sample_multi(edge_rnn_y_pred,num_of_samples=1)\n",
    "        #print(edge_rnn_y_pred_sampled.size(),node_x[:,:,j:j+1].size())\n",
    "        node_x[:,:,j:j+1] = edge_rnn_y_pred_sampled.view(edge_rnn_y_pred_sampled.size(0),\n",
    "                                                         edge_rnn_y_pred_sampled.size(1),1)\n",
    "        edge_x = edge_rnn_y_pred_sampled.long()\n",
    "    \n",
    "    \n",
    "    #print(node_label_sampled.size(),generated_graphs_labels[:,i+1,:].size())\n",
    "    generated_graphs_labels[:,i] = node_label_sampled\n",
    "    generated_graphs[:, i:i + 1, :] = node_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training graphs, max nodes, min nodes , max edges , min edges , max prev nodes 129 1 162 0 16\n"
     ]
    }
   ],
   "source": [
    "# # remove all zeros rows and columns\n",
    "# adj = adj[~np.all(adj == 0, axis=1)]\n",
    "# adj = adj[:, ~np.all(adj == 0, axis=0)]\n",
    "# adj = np.asmatrix(adj)\n",
    "# G = nx.from_numpy_matrix(adj)\n",
    "# return G\n",
    "\n",
    "def cut_graph(g,labels):\n",
    "    tp = np.where(~g.any(axis=1))[0]\n",
    "    if tp.shape[0] >0:\n",
    "        g = g[0:tp[0],:]\n",
    "        labels = labels[0:tp[0],:]\n",
    "    ct = 0\n",
    "    index = None\n",
    "    ct = 0\n",
    "    labels_list = []\n",
    "    for i in labels:\n",
    "        if i[0] == 0:### terminal node\n",
    "            index = ct\n",
    "            break\n",
    "        labels_list.append(i[0])\n",
    "        ct += 1\n",
    "    return (g[0:ct,:],labels_list)\n",
    "predicted_graphs = []\n",
    "predicted_graphs_x = []\n",
    "predicted_graphs_x_labels = []\n",
    "for i in range(num_graphs_to_be_generated):\n",
    "    pred_graph,pred_labels = cut_graph(generated_graphs[i].numpy(),generated_graphs_labels[i].numpy())\n",
    "    #pred_labels = [item[0] for item in generated_graphs_labels[i]]\n",
    "    #pred_graph = generated_graphs[i].numpy()\n",
    "    predicted_graphs.append(decode_M_matrix(pred_graph,M))\n",
    "    predicted_graphs_x.append(nx.from_numpy_matrix(predicted_graphs[i]))\n",
    "    start_label = node_x_label_1st_node[i,0].tolist()\n",
    "    pred_labels.insert(0,start_label)\n",
    "    predicted_graphs_x_labels.append(pred_labels)\n",
    "max_num_edges_test = max([graph.number_of_edges() for graph in predicted_graphs_x])\n",
    "min_num_edges_test = min([graph.number_of_edges() for graph in predicted_graphs_x])\n",
    "max_num_nodes_test = max([graph.number_of_nodes() for graph in predicted_graphs_x])\n",
    "min_num_nodes_test = min([graph.number_of_nodes() for graph in predicted_graphs_x])\n",
    "print(\"Number of training graphs, max nodes, min nodes , max edges , min edges , max prev nodes\", max_num_nodes_test, min_num_nodes_test, max_num_edges_test, min_num_edges_test,M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "threshold min nodes, max nodes, 9.608016506809733 65.3587593471912\n"
     ]
    }
   ],
   "source": [
    "mean_std_nodes = model_parameters['mean_std_nodes']\n",
    "thresh_min_nodes = mean_std_nodes[0] - 2*mean_std_nodes[1]\n",
    "thresh_max_nodes = mean_std_nodes[0] + 2*mean_std_nodes[1]\n",
    "print(\"threshold min nodes, max nodes,\" , thresh_min_nodes,thresh_max_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37.86277873070326\n",
      "583\n"
     ]
    }
   ],
   "source": [
    "predicted_graphs_x_index = [index for index,graph in enumerate(predicted_graphs_x) if (graph.number_of_nodes() >= thresh_min_nodes) and graph.number_of_nodes() <= thresh_max_nodes]\n",
    "predicted_graphs_x = list(map(predicted_graphs_x.__getitem__, predicted_graphs_x_index))\n",
    "predicted_graphs_x_labels = list(map(predicted_graphs_x_labels.__getitem__, predicted_graphs_x_index))\n",
    "print(np.mean([graph.number_of_nodes() for graph in predicted_graphs_x]))\n",
    "print(len(predicted_graphs_x))\n",
    "\n",
    "\n",
    "for i in range(0,len(predicted_graphs_x)):\n",
    "    g = predicted_graphs_x[i]\n",
    "    labels= predicted_graphs_x_labels[i]\n",
    "    for j in range(0,len(labels)):\n",
    "        g.node[j][\"node_label\"] = labels[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-87-a4effa93c9e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msave_graphs_nx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted_graphs_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"predicted_graph.txt\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnode_label_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0medge_label_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/COL761/project/graphrnn/code/read_graph.py\u001b[0m in \u001b[0;36msave_graphs_nx\u001b[0;34m(graphs, fname, node_label_dict, edge_label_dict)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber_of_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber_of_nodes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_label_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"node_label\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber_of_edges\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 4"
     ]
    }
   ],
   "source": [
    "save_graphs_nx(predicted_graphs_x,\"predicted_graph.txt\",node_label_dict,edge_label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2': 1, '1': 2, '3': 3}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edge_label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node label distribution , [(0.0, 3097), (1.0, 5076), (2.0, 26195), (3.0, 25935), (4.0, 44512), (5.0, 16895), (6.0, 1894), (7.0, 3254), (8.0, 194), (9.0, 706), (10.0, 106), (11.0, 136)]\n"
     ]
    }
   ],
   "source": [
    "a,b = np.unique(generated_graphs_labels,return_counts=True)\n",
    "print(\"node label distribution ,\", [i for i in zip(a,b)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
